{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd096a5d84734c2fcc0f1c4e29111ed2080412c48bc33f767562c76143427b08200",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "96a5d84734c2fcc0f1c4e29111ed2080412c48bc33f767562c76143427b08200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model assembly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Modell Auswahl\n",
    "\n",
    "Neuronales Netz, but WHY?????\n",
    "\n",
    "## Modellimplementierung"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LolProDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        data = pd.read_csv(data_file)\n",
    "        self.labels = torch.tensor(data.pop('Win Rate').to_numpy(), device=device)\n",
    "        self.features = torch.tensor(data.to_numpy(), device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.labels[idx])\n",
    "\n",
    "    def split(self, test_rate):\n",
    "        testc = int(self.__len__()*test_rate)\n",
    "        trainc = int(self.__len__() - testc)\n",
    "        return [trainc, testc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LolProNetwork(nn.Module):\n",
    "    def __init__(self, network_stack):\n",
    "        super(LolProNetwork, self).__init__()\n",
    "        self.network_stack = network_stack\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.network_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "\n",
    "network_stack = nn.Sequential(\n",
    "    nn.Linear(20, 128),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = LolProNetwork(network_stack).to(device).double()\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, optimizer):\n",
    "        size = len(dataloader.dataset)\n",
    "        test_loss, err = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y.unsqueeze(1)).item()\n",
    "                err += torch.abs(pred - y.unsqueeze(1)).sum().data\n",
    "        test_loss /= size\n",
    "        err /= size\n",
    "        print(f\"Test Error: \\n MAE: {(err):>8f}, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = LolProDataset('cleanDataTop+MidS10Final.csv')\n",
    "train_data, test_data = random_split(dataset, dataset.split(0.1), generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "h 18\n",
      "-------------------------------\n",
      "loss: 0.162490  [    0/  500]\n",
      "loss: 0.080401  [  100/  500]\n",
      "loss: 0.038230  [  200/  500]\n",
      "loss: 0.041508  [  300/  500]\n",
      "loss: 0.031028  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.107763, Avg loss: 0.107763 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.223830  [    0/  500]\n",
      "loss: 0.205742  [  100/  500]\n",
      "loss: 0.051936  [  200/  500]\n",
      "loss: 0.296225  [  300/  500]\n",
      "loss: 0.019244  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.108415, Avg loss: 0.108415 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.107615  [    0/  500]\n",
      "loss: 0.072413  [  100/  500]\n",
      "loss: 0.083707  [  200/  500]\n",
      "loss: 0.049833  [  300/  500]\n",
      "loss: 0.211436  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.105563, Avg loss: 0.105563 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.063651  [    0/  500]\n",
      "loss: 0.006262  [  100/  500]\n",
      "loss: 0.038567  [  200/  500]\n",
      "loss: 0.043569  [  300/  500]\n",
      "loss: 0.360763  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.106946, Avg loss: 0.106946 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.095846  [    0/  500]\n",
      "loss: 0.000793  [  100/  500]\n",
      "loss: 0.127630  [  200/  500]\n",
      "loss: 0.014031  [  300/  500]\n",
      "loss: 0.271703  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.105146, Avg loss: 0.105146 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.311404  [    0/  500]\n",
      "loss: 0.071962  [  100/  500]\n",
      "loss: 0.298852  [  200/  500]\n",
      "loss: 0.042888  [  300/  500]\n",
      "loss: 0.044656  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.107791, Avg loss: 0.107791 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.026257  [    0/  500]\n",
      "loss: 0.166615  [  100/  500]\n",
      "loss: 0.099278  [  200/  500]\n",
      "loss: 0.003015  [  300/  500]\n",
      "loss: 0.055565  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.109407, Avg loss: 0.109407 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.036724  [    0/  500]\n",
      "loss: 0.070407  [  100/  500]\n",
      "loss: 0.003237  [  200/  500]\n",
      "loss: 0.049128  [  300/  500]\n",
      "loss: 0.088610  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.105794, Avg loss: 0.105794 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.058049  [    0/  500]\n",
      "loss: 0.096676  [  100/  500]\n",
      "loss: 0.266548  [  200/  500]\n",
      "loss: 0.047668  [  300/  500]\n",
      "loss: 0.099065  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.108099, Avg loss: 0.108099 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.303945  [    0/  500]\n",
      "loss: 0.158088  [  100/  500]\n",
      "loss: 0.185340  [  200/  500]\n",
      "loss: 0.117264  [  300/  500]\n",
      "loss: 0.198280  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.107390, Avg loss: 0.107390 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.083636  [    0/  500]\n",
      "loss: 0.234146  [  100/  500]\n",
      "loss: 0.040703  [  200/  500]\n",
      "loss: 0.000952  [  300/  500]\n",
      "loss: 0.142198  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.106278, Avg loss: 0.106278 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.002932  [    0/  500]\n",
      "loss: 0.185889  [  100/  500]\n",
      "loss: 0.158907  [  200/  500]\n",
      "loss: 0.048204  [  300/  500]\n",
      "loss: 0.137722  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.106777, Avg loss: 0.106777 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.045208  [    0/  500]\n",
      "loss: 0.034268  [  100/  500]\n",
      "loss: 0.001819  [  200/  500]\n",
      "loss: 0.104755  [  300/  500]\n",
      "loss: 0.090122  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.104663, Avg loss: 0.104663 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.069159  [    0/  500]\n",
      "loss: 0.032740  [  100/  500]\n",
      "loss: 0.032445  [  200/  500]\n",
      "loss: 0.046384  [  300/  500]\n",
      "loss: 0.160785  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.106327, Avg loss: 0.106327 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.109128  [    0/  500]\n",
      "loss: 0.190694  [  100/  500]\n",
      "loss: 0.072288  [  200/  500]\n",
      "loss: 0.120301  [  300/  500]\n",
      "loss: 0.047931  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.103900, Avg loss: 0.103900 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.024082  [    0/  500]\n",
      "loss: 0.149871  [  100/  500]\n",
      "loss: 0.072473  [  200/  500]\n",
      "loss: 0.292240  [  300/  500]\n",
      "loss: 0.109923  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.104243, Avg loss: 0.104243 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.132409  [    0/  500]\n",
      "loss: 0.027381  [  100/  500]\n",
      "loss: 0.032590  [  200/  500]\n",
      "loss: 0.001443  [  300/  500]\n",
      "loss: 0.138764  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.105066, Avg loss: 0.105066 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.097760  [    0/  500]\n",
      "loss: 0.003387  [  100/  500]\n",
      "loss: 0.067042  [  200/  500]\n",
      "loss: 0.126673  [  300/  500]\n",
      "loss: 0.122660  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.104644, Avg loss: 0.104644 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.208575  [    0/  500]\n",
      "loss: 0.039676  [  100/  500]\n",
      "loss: 0.063074  [  200/  500]\n",
      "loss: 0.010597  [  300/  500]\n",
      "loss: 0.059234  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.101296, Avg loss: 0.101296 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.002947  [    0/  500]\n",
      "loss: 0.054264  [  100/  500]\n",
      "loss: 0.111585  [  200/  500]\n",
      "loss: 0.026517  [  300/  500]\n",
      "loss: 0.027415  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.101582, Avg loss: 0.101582 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.069297  [    0/  500]\n",
      "loss: 0.072752  [  100/  500]\n",
      "loss: 0.035408  [  200/  500]\n",
      "loss: 0.121280  [  300/  500]\n",
      "loss: 0.282755  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.101500, Avg loss: 0.101500 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.047562  [    0/  500]\n",
      "loss: 0.126403  [  100/  500]\n",
      "loss: 0.037227  [  200/  500]\n",
      "loss: 0.059436  [  300/  500]\n",
      "loss: 0.334783  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.102510, Avg loss: 0.102510 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.158720  [    0/  500]\n",
      "loss: 0.020518  [  100/  500]\n",
      "loss: 0.033430  [  200/  500]\n",
      "loss: 0.091943  [  300/  500]\n",
      "loss: 0.193469  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.102022, Avg loss: 0.102022 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.028822  [    0/  500]\n",
      "loss: 0.150546  [  100/  500]\n",
      "loss: 0.081776  [  200/  500]\n",
      "loss: 0.118218  [  300/  500]\n",
      "loss: 0.130984  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.103716, Avg loss: 0.103716 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.035378  [    0/  500]\n",
      "loss: 0.124025  [  100/  500]\n",
      "loss: 0.038774  [  200/  500]\n",
      "loss: 0.178380  [  300/  500]\n",
      "loss: 0.000600  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.102229, Avg loss: 0.102229 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.024649  [    0/  500]\n",
      "loss: 0.024123  [  100/  500]\n",
      "loss: 0.007898  [  200/  500]\n",
      "loss: 0.039290  [  300/  500]\n",
      "loss: 0.111002  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.101373, Avg loss: 0.101373 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.020437  [    0/  500]\n",
      "loss: 0.108126  [  100/  500]\n",
      "loss: 0.153469  [  200/  500]\n",
      "loss: 0.013750  [  300/  500]\n",
      "loss: 0.149818  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.101156, Avg loss: 0.101156 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.095059  [    0/  500]\n",
      "loss: 0.008142  [  100/  500]\n",
      "loss: 0.045632  [  200/  500]\n",
      "loss: 0.152741  [  300/  500]\n",
      "loss: 0.032395  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.099147, Avg loss: 0.099147 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.106303  [    0/  500]\n",
      "loss: 0.084765  [  100/  500]\n",
      "loss: 0.029607  [  200/  500]\n",
      "loss: 0.109718  [  300/  500]\n",
      "loss: 0.217764  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.097959, Avg loss: 0.097959 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.152575  [    0/  500]\n",
      "loss: 0.025164  [  100/  500]\n",
      "loss: 0.113819  [  200/  500]\n",
      "loss: 0.124399  [  300/  500]\n",
      "loss: 0.111777  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.097624, Avg loss: 0.097624 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.107068  [    0/  500]\n",
      "loss: 0.159316  [  100/  500]\n",
      "loss: 0.060931  [  200/  500]\n",
      "loss: 0.056822  [  300/  500]\n",
      "loss: 0.003122  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.100199, Avg loss: 0.100199 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.030856  [    0/  500]\n",
      "loss: 0.153274  [  100/  500]\n",
      "loss: 0.133262  [  200/  500]\n",
      "loss: 0.019326  [  300/  500]\n",
      "loss: 0.190242  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095716, Avg loss: 0.095716 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.037661  [    0/  500]\n",
      "loss: 0.018132  [  100/  500]\n",
      "loss: 0.092558  [  200/  500]\n",
      "loss: 0.015195  [  300/  500]\n",
      "loss: 0.112642  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.096266, Avg loss: 0.096266 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.031673  [    0/  500]\n",
      "loss: 0.089799  [  100/  500]\n",
      "loss: 0.148782  [  200/  500]\n",
      "loss: 0.031292  [  300/  500]\n",
      "loss: 0.001339  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095783, Avg loss: 0.095783 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.053861  [    0/  500]\n",
      "loss: 0.139267  [  100/  500]\n",
      "loss: 0.024579  [  200/  500]\n",
      "loss: 0.168608  [  300/  500]\n",
      "loss: 0.038419  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.096121, Avg loss: 0.096121 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.031975  [    0/  500]\n",
      "loss: 0.080213  [  100/  500]\n",
      "loss: 0.226912  [  200/  500]\n",
      "loss: 0.016314  [  300/  500]\n",
      "loss: 0.006963  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095685, Avg loss: 0.095685 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.135320  [    0/  500]\n",
      "loss: 0.204416  [  100/  500]\n",
      "loss: 0.125700  [  200/  500]\n",
      "loss: 0.009424  [  300/  500]\n",
      "loss: 0.079112  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095794, Avg loss: 0.095794 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.142909  [    0/  500]\n",
      "loss: 0.037929  [  100/  500]\n",
      "loss: 0.183979  [  200/  500]\n",
      "loss: 0.142710  [  300/  500]\n",
      "loss: 0.203888  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095698, Avg loss: 0.095698 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.033419  [    0/  500]\n",
      "loss: 0.125348  [  100/  500]\n",
      "loss: 0.108895  [  200/  500]\n",
      "loss: 0.005916  [  300/  500]\n",
      "loss: 0.045026  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094868, Avg loss: 0.094868 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.201268  [    0/  500]\n",
      "loss: 0.104748  [  100/  500]\n",
      "loss: 0.146817  [  200/  500]\n",
      "loss: 0.007274  [  300/  500]\n",
      "loss: 0.135657  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.097235, Avg loss: 0.097235 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.017947  [    0/  500]\n",
      "loss: 0.004652  [  100/  500]\n",
      "loss: 0.211284  [  200/  500]\n",
      "loss: 0.069898  [  300/  500]\n",
      "loss: 0.172518  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094020, Avg loss: 0.094020 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.067673  [    0/  500]\n",
      "loss: 0.056277  [  100/  500]\n",
      "loss: 0.144846  [  200/  500]\n",
      "loss: 0.043850  [  300/  500]\n",
      "loss: 0.049574  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.099467, Avg loss: 0.099467 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.090919  [    0/  500]\n",
      "loss: 0.043757  [  100/  500]\n",
      "loss: 0.021139  [  200/  500]\n",
      "loss: 0.037082  [  300/  500]\n",
      "loss: 0.173446  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095358, Avg loss: 0.095358 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.126985  [    0/  500]\n",
      "loss: 0.212050  [  100/  500]\n",
      "loss: 0.068794  [  200/  500]\n",
      "loss: 0.045022  [  300/  500]\n",
      "loss: 0.069184  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095303, Avg loss: 0.095303 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.024527  [    0/  500]\n",
      "loss: 0.030728  [  100/  500]\n",
      "loss: 0.053594  [  200/  500]\n",
      "loss: 0.224348  [  300/  500]\n",
      "loss: 0.005124  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.092606, Avg loss: 0.092606 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.009829  [    0/  500]\n",
      "loss: 0.199440  [  100/  500]\n",
      "loss: 0.106438  [  200/  500]\n",
      "loss: 0.017515  [  300/  500]\n",
      "loss: 0.024256  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.098417, Avg loss: 0.098417 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.101339  [    0/  500]\n",
      "loss: 0.004535  [  100/  500]\n",
      "loss: 0.104645  [  200/  500]\n",
      "loss: 0.009393  [  300/  500]\n",
      "loss: 0.064115  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.098067, Avg loss: 0.098067 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.082764  [    0/  500]\n",
      "loss: 0.038245  [  100/  500]\n",
      "loss: 0.031948  [  200/  500]\n",
      "loss: 0.121539  [  300/  500]\n",
      "loss: 0.122607  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.097344, Avg loss: 0.097344 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.020419  [    0/  500]\n",
      "loss: 0.046211  [  100/  500]\n",
      "loss: 0.005655  [  200/  500]\n",
      "loss: 0.322609  [  300/  500]\n",
      "loss: 0.067731  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093895, Avg loss: 0.093895 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.005966  [    0/  500]\n",
      "loss: 0.156784  [  100/  500]\n",
      "loss: 0.116735  [  200/  500]\n",
      "loss: 0.056806  [  300/  500]\n",
      "loss: 0.167749  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095802, Avg loss: 0.095802 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.121277  [    0/  500]\n",
      "loss: 0.001112  [  100/  500]\n",
      "loss: 0.012006  [  200/  500]\n",
      "loss: 0.025588  [  300/  500]\n",
      "loss: 0.189989  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093233, Avg loss: 0.093233 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.113528  [    0/  500]\n",
      "loss: 0.032699  [  100/  500]\n",
      "loss: 0.111430  [  200/  500]\n",
      "loss: 0.043514  [  300/  500]\n",
      "loss: 0.031891  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094218, Avg loss: 0.094218 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.090793  [    0/  500]\n",
      "loss: 0.060155  [  100/  500]\n",
      "loss: 0.209764  [  200/  500]\n",
      "loss: 0.004106  [  300/  500]\n",
      "loss: 0.050610  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094072, Avg loss: 0.094072 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.079325  [    0/  500]\n",
      "loss: 0.073871  [  100/  500]\n",
      "loss: 0.006982  [  200/  500]\n",
      "loss: 0.029424  [  300/  500]\n",
      "loss: 0.018021  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094145, Avg loss: 0.094145 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.077972  [    0/  500]\n",
      "loss: 0.025459  [  100/  500]\n",
      "loss: 0.063960  [  200/  500]\n",
      "loss: 0.124724  [  300/  500]\n",
      "loss: 0.027508  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095887, Avg loss: 0.095887 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.179706  [    0/  500]\n",
      "loss: 0.055544  [  100/  500]\n",
      "loss: 0.026878  [  200/  500]\n",
      "loss: 0.024021  [  300/  500]\n",
      "loss: 0.003086  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.096837, Avg loss: 0.096837 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.023999  [    0/  500]\n",
      "loss: 0.021993  [  100/  500]\n",
      "loss: 0.199430  [  200/  500]\n",
      "loss: 0.029130  [  300/  500]\n",
      "loss: 0.040043  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093276, Avg loss: 0.093276 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.107453  [    0/  500]\n",
      "loss: 0.049766  [  100/  500]\n",
      "loss: 0.022055  [  200/  500]\n",
      "loss: 0.037289  [  300/  500]\n",
      "loss: 0.040547  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095040, Avg loss: 0.095040 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.065952  [    0/  500]\n",
      "loss: 0.010201  [  100/  500]\n",
      "loss: 0.115976  [  200/  500]\n",
      "loss: 0.108205  [  300/  500]\n",
      "loss: 0.090043  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095027, Avg loss: 0.095027 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.017700  [    0/  500]\n",
      "loss: 0.068742  [  100/  500]\n",
      "loss: 0.173665  [  200/  500]\n",
      "loss: 0.172384  [  300/  500]\n",
      "loss: 0.161740  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095230, Avg loss: 0.095230 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.105800  [    0/  500]\n",
      "loss: 0.125692  [  100/  500]\n",
      "loss: 0.133855  [  200/  500]\n",
      "loss: 0.173821  [  300/  500]\n",
      "loss: 0.035141  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095459, Avg loss: 0.095459 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.009818  [    0/  500]\n",
      "loss: 0.106073  [  100/  500]\n",
      "loss: 0.074725  [  200/  500]\n",
      "loss: 0.110627  [  300/  500]\n",
      "loss: 0.121638  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094405, Avg loss: 0.094405 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.177913  [    0/  500]\n",
      "loss: 0.085506  [  100/  500]\n",
      "loss: 0.042069  [  200/  500]\n",
      "loss: 0.048232  [  300/  500]\n",
      "loss: 0.214248  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093311, Avg loss: 0.093311 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.019635  [    0/  500]\n",
      "loss: 0.000532  [  100/  500]\n",
      "loss: 0.026851  [  200/  500]\n",
      "loss: 0.017983  [  300/  500]\n",
      "loss: 0.069679  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093099, Avg loss: 0.093099 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.089353  [    0/  500]\n",
      "loss: 0.088542  [  100/  500]\n",
      "loss: 0.008059  [  200/  500]\n",
      "loss: 0.071848  [  300/  500]\n",
      "loss: 0.044292  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.092814, Avg loss: 0.092814 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.010992  [    0/  500]\n",
      "loss: 0.052163  [  100/  500]\n",
      "loss: 0.066014  [  200/  500]\n",
      "loss: 0.036837  [  300/  500]\n",
      "loss: 0.115264  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.098369, Avg loss: 0.098369 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.004615  [    0/  500]\n",
      "loss: 0.016280  [  100/  500]\n",
      "loss: 0.115621  [  200/  500]\n",
      "loss: 0.069263  [  300/  500]\n",
      "loss: 0.050358  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093108, Avg loss: 0.093108 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.138640  [    0/  500]\n",
      "loss: 0.183651  [  100/  500]\n",
      "loss: 0.164043  [  200/  500]\n",
      "loss: 0.149543  [  300/  500]\n",
      "loss: 0.100334  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.092374, Avg loss: 0.092374 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.019991  [    0/  500]\n",
      "loss: 0.203071  [  100/  500]\n",
      "loss: 0.052437  [  200/  500]\n",
      "loss: 0.082078  [  300/  500]\n",
      "loss: 0.100542  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095439, Avg loss: 0.095439 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.041409  [    0/  500]\n",
      "loss: 0.022336  [  100/  500]\n",
      "loss: 0.002626  [  200/  500]\n",
      "loss: 0.238203  [  300/  500]\n",
      "loss: 0.016538  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.095126, Avg loss: 0.095126 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.008522  [    0/  500]\n",
      "loss: 0.289689  [  100/  500]\n",
      "loss: 0.023553  [  200/  500]\n",
      "loss: 0.006376  [  300/  500]\n",
      "loss: 0.111820  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094877, Avg loss: 0.094877 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.039228  [    0/  500]\n",
      "loss: 0.026750  [  100/  500]\n",
      "loss: 0.002808  [  200/  500]\n",
      "loss: 0.054391  [  300/  500]\n",
      "loss: 0.063758  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.097555, Avg loss: 0.097555 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.006637  [    0/  500]\n",
      "loss: 0.038977  [  100/  500]\n",
      "loss: 0.084028  [  200/  500]\n",
      "loss: 0.019847  [  300/  500]\n",
      "loss: 0.088310  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.100212, Avg loss: 0.100212 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.036355  [    0/  500]\n",
      "loss: 0.055855  [  100/  500]\n",
      "loss: 0.004563  [  200/  500]\n",
      "loss: 0.054484  [  300/  500]\n",
      "loss: 0.013969  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094986, Avg loss: 0.094986 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.221457  [    0/  500]\n",
      "loss: 0.221292  [  100/  500]\n",
      "loss: 0.050424  [  200/  500]\n",
      "loss: 0.066159  [  300/  500]\n",
      "loss: 0.060616  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093595, Avg loss: 0.093595 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.044342  [    0/  500]\n",
      "loss: 0.092739  [  100/  500]\n",
      "loss: 0.093616  [  200/  500]\n",
      "loss: 0.193141  [  300/  500]\n",
      "loss: 0.047423  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.092837, Avg loss: 0.092837 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.171430  [    0/  500]\n",
      "loss: 0.365239  [  100/  500]\n",
      "loss: 0.083501  [  200/  500]\n",
      "loss: 0.014647  [  300/  500]\n",
      "loss: 0.051863  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.096759, Avg loss: 0.096759 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.019038  [    0/  500]\n",
      "loss: 0.090249  [  100/  500]\n",
      "loss: 0.234331  [  200/  500]\n",
      "loss: 0.032431  [  300/  500]\n",
      "loss: 0.046857  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094539, Avg loss: 0.094539 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.013965  [    0/  500]\n",
      "loss: 0.138297  [  100/  500]\n",
      "loss: 0.030202  [  200/  500]\n",
      "loss: 0.065269  [  300/  500]\n",
      "loss: 0.077057  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.093749, Avg loss: 0.093749 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.109250  [    0/  500]\n",
      "loss: 0.112649  [  100/  500]\n",
      "loss: 0.038543  [  200/  500]\n",
      "loss: 0.137859  [  300/  500]\n",
      "loss: 0.142398  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.102743, Avg loss: 0.102743 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.228281  [    0/  500]\n",
      "loss: 0.005882  [  100/  500]\n",
      "loss: 0.185725  [  200/  500]\n",
      "loss: 0.061292  [  300/  500]\n",
      "loss: 0.011912  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.092960, Avg loss: 0.092960 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.024093  [    0/  500]\n",
      "loss: 0.073793  [  100/  500]\n",
      "loss: 0.025503  [  200/  500]\n",
      "loss: 0.073749  [  300/  500]\n",
      "loss: 0.020989  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.094912, Avg loss: 0.094912 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.144042  [    0/  500]\n",
      "loss: 0.017613  [  100/  500]\n",
      "loss: 0.007052  [  200/  500]\n",
      "loss: 0.094227  [  300/  500]\n",
      "loss: 0.053165  [  400/  500]\n",
      "Test Error: \n",
      " MAE: 0.102169, Avg loss: 0.102169 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5979], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "my_test = [100, 5, 4, 1.5, 3.5, 9, 450, 0.5, 0.2, 600, 1.3, 0.6, 0.2, 0.3, 500, 30, 400, 0.3, 0.05, 40]\n",
    "my_test_tensor = torch.tensor(my_test, device=device).double()\n",
    "model(my_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}