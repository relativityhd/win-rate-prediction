{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd096a5d84734c2fcc0f1c4e29111ed2080412c48bc33f767562c76143427b08200",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "96a5d84734c2fcc0f1c4e29111ed2080412c48bc33f767562c76143427b08200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model assembly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Modell Auswahl\n",
    "\n",
    "Neuronales Netz, but WHY?????\n",
    "\n",
    "## Modellimplementierung"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "###### Imports\n",
    "Importiert die Bibliotheken PyTorch und Pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "###### Device\n",
    "Bestimmt ob auf der Grafikkarte oder auf dem Prozessor gerechnet werden soll. Wenn eine CUDA fähige Grafikkarte erkannt wird, wird diese als Rechengerät ausgewählt. Dies spart Rechenzeit, da CUDA Kerne deutlich effizienter in der Berechnung Neuronaler Netze sind."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "source": [
    "###### PyTorch Klassen\n",
    "Definiert eine Klasse für das Datenset und eine für das Neuronale Netzwerk."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LolProDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        # Preload data into tensors\n",
    "        data = pd.read_csv(data_file)\n",
    "        self.labels = torch.tensor(data.pop('Win Rate').to_numpy(), device=device)\n",
    "        self.features = torch.tensor(data.to_numpy(), device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of rows in the dataset\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns item (features, label) at specific index\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "        return (x, y)\n",
    "\n",
    "    def split(self, test_rate):\n",
    "        # Returns number of items for test and train sets by given test_rate\n",
    "        testc = int(self.__len__()*test_rate)\n",
    "        trainc = int(self.__len__() - testc)\n",
    "        return [trainc, testc]\n",
    "\n",
    "# This is just a wrapper for the network_stack which implements the Neural Network\n",
    "class LolProNetwork(nn.Module):\n",
    "    def __init__(self, network_stack):\n",
    "        super(LolProNetwork, self).__init__()\n",
    "        self.network_stack = network_stack\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network_stack(x)"
   ]
  },
  {
   "source": [
    "###### Train and Test Loops\n",
    "Loops in which the Neural Net gets trained and tested"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # Train Loop: trains the Neural Network\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # Test Loop: Tests the Neural Network\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, err = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.unsqueeze(1)).item()\n",
    "            err += torch.abs(pred - y.unsqueeze(1)).sum().data\n",
    "    test_loss /= size\n",
    "    err /= size\n",
    "    return (err.item(), test_loss)"
   ]
  },
  {
   "source": [
    "###### Run Code\n",
    "Set parameters, define Network, loss function and optimizer, load in Dataset and train the network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.0001 # Learning Rate\n",
    "batch_size = 20 # Batch Size (Parallel calculated rows)\n",
    "epochs = 10000 # Epochs (iterations over dataset)\n",
    "\n",
    "# Network\n",
    "network_stack = nn.Sequential(\n",
    "    nn.Linear(20, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Generate Model from Network and push it to the specified device and set dtype to double\n",
    "model = LolProNetwork(network_stack).to(device).double()\n",
    "\n",
    "loss_fn = nn.L1Loss() # MAE Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr) # Optimizer\n",
    "\n",
    "# Load Dataset\n",
    "dataset = LolProDataset('cleanDataTop+MidS10Final.csv')\n",
    "train_data, test_data = random_split(dataset, dataset.split(0.1), generator=torch.Generator().manual_seed(42))\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train and test in epochs\n",
    "history = pd.DataFrame([], columns=[\"Epoch\", \"MAE\", \"Loss\"])\n",
    "for t in range(epochs):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    res = test_loop(test_dataloader, model, loss_fn, optimizer)\n",
    "    history = history.append({\"Epoch\": t+1, \"MAE\": res[0], \"Loss\": res[1]}, ignore_index=True)\n",
    "    if (t+1)%100 == 0:\n",
    "        print(f\"Epoch {t+1} - MAE: {res[0]}, Loss: {res[1]}\")"
   ]
  },
  {
   "source": [
    "###### Visualize results\n",
    "Visualize history with matplotlib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['Epoch'], history['MAE'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['Epoch'], history['Loss'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own stuff, gets deleted soon\n",
    "my_test = [100, 5, 4, 1.5, 3.5, 9, 450, 0.5, 0.2, 600, 1.3, 0.6, 0.2, 0.3, 500, 30, 400, 0.3, 0.05, 40]\n",
    "my_test_tensor = torch.tensor(my_test, device=device).double()\n",
    "model(my_test_tensor)"
   ]
  }
 ]
}